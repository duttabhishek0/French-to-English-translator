{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NwAAPrdNFoH0"
   },
   "source": [
    "Downloading the [Zip file](http://www.manythings.org/anki/fra-eng.zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UDBptzV8z6Lj",
    "outputId": "6758a032-30ed-4af2-c741-aa059f42e129"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2022-03-11 12:21:37--  http://www.manythings.org/anki/fra-eng.zip\n",
      "Resolving www.manythings.org (www.manythings.org)... 104.21.92.44, 172.67.186.54\n",
      "Connecting to www.manythings.org (www.manythings.org)|104.21.92.44|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 6532197 (6.2M) [application/zip]\n",
      "Saving to: 'fra-eng.zip'\n",
      "\n",
      "     0K .......... .......... .......... .......... ..........  0% 1.19M 5s\n",
      "    50K .......... .......... .......... .......... ..........  1% 10.4M 3s\n",
      "   100K .......... .......... .......... .......... ..........  2%  805K 4s\n",
      "   150K .......... .......... .......... .......... ..........  3%  150K 14s\n",
      "   200K .......... .......... .......... .......... ..........  3% 8.57M 11s\n",
      "   250K .......... .......... .......... .......... ..........  4% 4.94M 9s\n",
      "   300K .......... .......... .......... .......... ..........  5% 10.2M 8s\n",
      "   350K .......... .......... .......... .......... ..........  6% 6.01M 7s\n",
      "   400K .......... .......... .......... .......... ..........  7%  736K 7s\n",
      "   450K .......... .......... .......... .......... ..........  7%  424K 8s\n",
      "   500K .......... .......... .......... .......... ..........  8% 14.6M 7s\n",
      "   550K .......... .......... .......... .......... ..........  9% 22.4M 6s\n",
      "   600K .......... .......... .......... .......... .......... 10% 12.9M 6s\n",
      "   650K .......... .......... .......... .......... .......... 10% 18.9M 5s\n",
      "   700K .......... .......... .......... .......... .......... 11% 2.92M 5s\n",
      "   750K .......... .......... .......... .......... .......... 12%  452K 6s\n",
      "   800K .......... .......... .......... .......... .......... 13% 7.83M 5s\n",
      "   850K .......... .......... .......... .......... .......... 14% 10.2M 5s\n",
      "   900K .......... .......... .......... .......... .......... 14% 20.7M 5s\n",
      "   950K .......... .......... .......... .......... .......... 15% 12.0M 4s\n",
      "  1000K .......... .......... .......... .......... .......... 16% 7.05M 4s\n",
      "  1050K .......... .......... .......... .......... .......... 17%  496K 4s\n",
      "  1100K .......... .......... .......... .......... .......... 18% 20.7M 4s\n",
      "  1150K .......... .......... .......... .......... .......... 18% 30.0M 4s\n",
      "  1200K .......... .......... .......... .......... .......... 19% 15.8M 4s\n",
      "  1250K .......... .......... .......... .......... .......... 20% 17.6M 4s\n",
      "  1300K .......... .......... .......... .......... .......... 21% 28.0M 3s\n",
      "  1350K .......... .......... .......... .......... .......... 21% 2.09M 3s\n",
      "  1400K .......... .......... .......... .......... .......... 22% 1.37M 3s\n",
      "  1450K .......... .......... .......... .......... .......... 23% 7.20M 3s\n",
      "  1500K .......... .......... .......... .......... .......... 24% 4.37M 3s\n",
      "  1550K .......... .......... .......... .......... .......... 25% 1.27M 3s\n",
      "  1600K .......... .......... .......... .......... .......... 25% 6.12M 3s\n",
      "  1650K .......... .......... .......... .......... .......... 26% 5.56M 3s\n",
      "  1700K .......... .......... .......... .......... .......... 27% 11.1M 3s\n",
      "  1750K .......... .......... .......... .......... .......... 28% 6.99M 3s\n",
      "  1800K .......... .......... .......... .......... .......... 29% 2.73M 3s\n",
      "  1850K .......... .......... .......... .......... .......... 29% 2.57M 3s\n",
      "  1900K .......... .......... .......... .......... .......... 30% 5.83M 3s\n",
      "  1950K .......... .......... .......... .......... .......... 31% 2.75M 2s\n",
      "  2000K .......... .......... .......... .......... .......... 32% 2.45M 2s\n",
      "  2050K .......... .......... .......... .......... .......... 32% 11.8M 2s\n",
      "  2100K .......... .......... .......... .......... .......... 33% 4.34M 2s\n",
      "  2150K .......... .......... .......... .......... .......... 34% 1.69M 2s\n",
      "  2200K .......... .......... .......... .......... .......... 35% 7.92M 2s\n",
      "  2250K .......... .......... .......... .......... .......... 36% 2.54M 2s\n",
      "  2300K .......... .......... .......... .......... .......... 36% 11.6M 2s\n",
      "  2350K .......... .......... .......... .......... .......... 37% 8.25M 2s\n",
      "  2400K .......... .......... .......... .......... .......... 38% 2.56M 2s\n",
      "  2450K .......... .......... .......... .......... .......... 39% 3.21M 2s\n",
      "  2500K .......... .......... .......... .......... .......... 39% 7.12M 2s\n",
      "  2550K .......... .......... .......... .......... .......... 40% 6.86M 2s\n",
      "  2600K .......... .......... .......... .......... .......... 41% 6.00M 2s\n",
      "  2650K .......... .......... .......... .......... .......... 42% 6.54M 2s\n",
      "  2700K .......... .......... .......... .......... .......... 43% 2.95M 2s\n",
      "  2750K .......... .......... .......... .......... .......... 43% 5.20M 2s\n",
      "  2800K .......... .......... .......... .......... .......... 44% 4.02M 2s\n",
      "  2850K .......... .......... .......... .......... .......... 45% 4.69M 2s\n",
      "  2900K .......... .......... .......... .......... .......... 46% 5.84M 2s\n",
      "  2950K .......... .......... .......... .......... .......... 47% 6.85M 2s\n",
      "  3000K .......... .......... .......... .......... .......... 47% 7.14M 1s\n",
      "  3050K .......... .......... .......... .......... .......... 48% 4.06M 1s\n",
      "  3100K .......... .......... .......... .......... .......... 49% 9.15M 1s\n",
      "  3150K .......... .......... .......... .......... .......... 50% 3.34M 1s\n",
      "  3200K .......... .......... .......... .......... .......... 50% 13.9M 1s\n",
      "  3250K .......... .......... .......... .......... .......... 51%  847K 1s\n",
      "  3300K .......... .......... .......... .......... .......... 52% 4.05M 1s\n",
      "  3350K .......... .......... .......... .......... .......... 53% 2.34M 1s\n",
      "  3400K .......... .......... .......... .......... .......... 54% 13.8M 1s\n",
      "  3450K .......... .......... .......... .......... .......... 54% 6.16M 1s\n",
      "  3500K .......... .......... .......... .......... .......... 55% 2.60M 1s\n",
      "  3550K .......... .......... .......... .......... .......... 56% 4.92M 1s\n",
      "  3600K .......... .......... .......... .......... .......... 57% 12.3M 1s\n",
      "  3650K .......... .......... .......... .......... .......... 58% 2.82M 1s\n",
      "  3700K .......... .......... .......... .......... .......... 58% 4.96M 1s\n",
      "  3750K .......... .......... .......... .......... .......... 59% 6.88M 1s\n",
      "  3800K .......... .......... .......... .......... .......... 60% 9.50M 1s\n",
      "  3850K .......... .......... .......... .......... .......... 61% 8.17M 1s\n",
      "  3900K .......... .......... .......... .......... .......... 61%  238K 1s\n",
      "  3950K .......... .......... .......... .......... .......... 62% 8.48M 1s\n",
      "  4000K .......... .......... .......... .......... .......... 63% 8.54M 1s\n",
      "  4050K .......... .......... .......... .......... .......... 64% 7.85M 1s\n",
      "  4100K .......... .......... .......... .......... .......... 65% 20.7M 1s\n",
      "  4150K .......... .......... .......... .......... .......... 65% 33.0M 1s\n",
      "  4200K .......... .......... .......... .......... .......... 66% 36.6M 1s\n",
      "  4250K .......... .......... .......... .......... .......... 67% 23.7M 1s\n",
      "  4300K .......... .......... .......... .......... .......... 68% 23.2M 1s\n",
      "  4350K .......... .......... .......... .......... .......... 68% 32.2M 1s\n",
      "  4400K .......... .......... .......... .......... .......... 69% 12.5M 1s\n",
      "  4450K .......... .......... .......... .......... .......... 70% 12.4M 1s\n",
      "  4500K .......... .......... .......... .......... .......... 71% 22.0M 1s\n",
      "  4550K .......... .......... .......... .......... .......... 72% 9.74M 1s\n",
      "  4600K .......... .......... .......... .......... .......... 72% 24.9M 1s\n",
      "  4650K .......... .......... .......... .......... .......... 73% 16.6M 1s\n",
      "  4700K .......... .......... .......... .......... .......... 74% 21.5M 1s\n",
      "  4750K .......... .......... .......... .......... .......... 75% 30.4M 1s\n",
      "  4800K .......... .......... .......... .......... .......... 76% 40.4M 1s\n",
      "  4850K .......... .......... .......... .......... .......... 76% 11.5M 1s\n",
      "  4900K .......... .......... .......... .......... .......... 77% 21.4M 1s\n",
      "  4950K .......... .......... .......... .......... .......... 78% 1.03M 1s\n",
      "  5000K .......... .......... .......... .......... .......... 79% 2.81M 1s\n",
      "  5050K .......... .......... .......... .......... .......... 79% 4.60M 0s\n",
      "  5100K .......... .......... .......... .......... .......... 80% 7.17M 0s\n",
      "  5150K .......... .......... .......... .......... .......... 81% 3.33M 0s\n",
      "  5200K .......... .......... .......... .......... .......... 82% 4.80M 0s\n",
      "  5250K .......... .......... .......... .......... .......... 83% 7.41M 0s\n",
      "  5300K .......... .......... .......... .......... .......... 83% 5.08M 0s\n",
      "  5350K .......... .......... .......... .......... .......... 84% 3.90M 0s\n",
      "  5400K .......... .......... .......... .......... .......... 85% 13.9M 0s\n",
      "  5450K .......... .......... .......... .......... .......... 86% 1.69M 0s\n",
      "  5500K .......... .......... .......... .......... .......... 87% 18.5M 0s\n",
      "  5550K .......... .......... .......... .......... .......... 87% 37.9M 0s\n",
      "  5600K .......... .......... .......... .......... .......... 88% 24.8M 0s\n",
      "  5650K .......... .......... .......... .......... .......... 89% 19.7M 0s\n",
      "  5700K .......... .......... .......... .......... .......... 90% 5.46M 0s\n",
      "  5750K .......... .......... .......... .......... .......... 90% 5.70M 0s\n",
      "  5800K .......... .......... .......... .......... .......... 91% 10.1M 0s\n",
      "  5850K .......... .......... .......... .......... .......... 92% 3.73M 0s\n",
      "  5900K .......... .......... .......... .......... .......... 93% 8.51M 0s\n",
      "  5950K .......... .......... .......... .......... .......... 94% 4.31M 0s\n",
      "  6000K .......... .......... .......... .......... .......... 94% 18.3M 0s\n",
      "  6050K .......... .......... .......... .......... .......... 95% 3.95M 0s\n",
      "  6100K .......... .......... .......... .......... .......... 96% 19.6M 0s\n",
      "  6150K .......... .......... .......... .......... .......... 97% 9.47M 0s\n",
      "  6200K .......... .......... .......... .......... .......... 97% 5.77M 0s\n",
      "  6250K .......... .......... .......... .......... .......... 98% 8.68M 0s\n",
      "  6300K .......... .......... .......... .......... .......... 99% 19.5M 0s\n",
      "  6350K .......... .......... .........                       100% 3.70M=2.1s\n",
      "\n",
      "2022-03-11 12:21:41 (2.92 MB/s) - 'fra-eng.zip' saved [6532197/6532197]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://www.manythings.org/anki/fra-eng.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SqmsUr54GM8M"
   },
   "source": [
    "**Extracting the Zip file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "R7_XKmpIJFT1"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "zip = zipfile.ZipFile('fra-eng.zip')\n",
    "zip.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-JIkRGU6GTrj"
   },
   "source": [
    "**Dependencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "F1NLrlQkMHhH"
   },
   "outputs": [],
   "source": [
    "import string,re\n",
    "from unicodedata import normalize\n",
    "from numpy import array,argmax\n",
    "from pickle import load,dump\n",
    "from numpy.random import rand,shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "dvlzRVWJGeq8"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import LSTM,Dense,Embedding,RepeatVector,TimeDistributed\n",
    "from nltk.translate.bleu_score import SmoothingFunction,corpus_bleu\n",
    "smoothie = SmoothingFunction().method4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Di1MTtIJugr"
   },
   "source": [
    "**Loading the file and reading the content of the file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "p1uiIFmaLbZg"
   },
   "outputs": [],
   "source": [
    "# load file into memory\n",
    "def load_file(filename):\n",
    "\t# open the file as read only\n",
    "\tfile = open(filename, mode='rt', encoding='utf-8')\n",
    "\t# read all text\n",
    "\ttext = file.read()\n",
    "\t# close the file\n",
    "\tfile.close()\n",
    "\treturn text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UQ6vhjhDJ5jy"
   },
   "source": [
    "**Splitting the sentence into pairs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "QV6559a1LvQI"
   },
   "outputs": [],
   "source": [
    "# split a loaded document into sentences\n",
    "def splitting_sentence(doc):\n",
    "\tsentences = doc.strip().split('\\n')\n",
    "\tpairs = [sentence.split('\\t') for sentence in  sentences]\n",
    "\treturn pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bc2F_iwDKCAC"
   },
   "source": [
    "**Cleaning the pairs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "2p-ZO41bL3U3"
   },
   "outputs": [],
   "source": [
    "# cleaning a list of sentences and creating pairs\n",
    "\n",
    "def clean_pairs(sentences):\n",
    "\tcleaned = list()\n",
    " \n",
    "\t# preparing regex for char filtering\n",
    "\tre_print = re.compile('[^%s]' % re.escape(string.printable))\n",
    "\n",
    "\t# preparing translation table for removing punctuation\n",
    "\ttable = str.maketrans('', '', string.punctuation)\n",
    "\n",
    "  # iterating over each pair\n",
    "\tfor pair in sentences:\n",
    "\t\tclean_pair = list()\n",
    "  \n",
    "\t\tfor sentence in pair:\n",
    "\t\t\t# normalizing unicode characters\n",
    "\t\t\tsentence = normalize('NFD', sentence).encode('ascii', 'ignore')\n",
    "\t\t\tsentence = sentence.decode('UTF-8')\n",
    "\t\t\t# tokenizing on white space\n",
    "\t\t\tsentence = sentence.split()\n",
    "\t\t\t# converting to lowercase\n",
    "\t\t\tsentence = [word.lower() for word in sentence]\n",
    "\t\t\t# removing punctuation from each token\n",
    "\t\t\tsentence = [word.translate(table) for word in sentence]\n",
    "\t\t\t# removing non-printable chars form each token\n",
    "\t\t\tsentence = [re_print.sub('', w) for w in sentence]\n",
    "\t\t\t# removing tokens with numbers in them\n",
    "\t\t\tsentence = [word for word in sentence if word.isalpha()]\n",
    "\t\t\t# storing as string\n",
    "\t\t\tclean_pair.append(' '.join(sentence))\n",
    "\t\tcleaned.append(clean_pair)\n",
    "\treturn array(cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IfpzMDIDMIvC"
   },
   "source": [
    "**Saving the Cleaned data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Ovtlpsp3MVU_"
   },
   "outputs": [],
   "source": [
    "def saving_clean_data(sentences, filename):\n",
    "\tdump(sentences, open(filename, 'wb'))\n",
    "\tprint(filename,': Saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b3RLnKIVMO5J"
   },
   "source": [
    "**Saving data in .pkl format**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0tkoxnpbMjLn",
    "outputId": "4d699ce9-a303-4fba-f01c-ab8603e5ee95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "english-french.pkl : Saved\n",
      "English --> French\n",
      "go --> va\n",
      "go --> marche\n",
      "go --> bouge\n",
      "hi --> salut\n",
      "hi --> salut\n",
      "run --> cours\n",
      "run --> courez\n",
      "run --> prenez vos jambes a vos cous\n",
      "run --> file\n",
      "run --> filez\n",
      "run --> cours\n",
      "run --> fuyez\n",
      "run --> fuyons\n",
      "run --> cours\n",
      "run --> courez\n",
      "run --> prenez vos jambes a vos cous\n",
      "run --> file\n",
      "run --> filez\n",
      "run --> cours\n",
      "run --> fuyez\n",
      "run --> fuyons\n",
      "who --> qui\n",
      "wow --> ca alors\n",
      "duck --> a terre\n",
      "duck --> baissetoi\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "\n",
    "filename = 'fra.txt'\n",
    "doc = load_file(filename)\n",
    "\n",
    "# split into english-french pairs\n",
    "pairs = splitting_sentence(doc)\n",
    "\n",
    "# clean sentences\n",
    "clean_pairs = clean_pairs(pairs)\n",
    "\n",
    "# save clean pairs to file\n",
    "saving_clean_data(clean_pairs, 'english-french.pkl')\n",
    "\n",
    "print('English','-->',\"French\")\n",
    "# spot check\n",
    "for i in range(25):\n",
    "\tprint(clean_pairs[i,0],'-->',clean_pairs[i,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gq5SVqTtcQtS"
   },
   "source": [
    "**Loading the cleaned data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "L5oB73alcVRO"
   },
   "outputs": [],
   "source": [
    "# load a clean dataset\n",
    "def loading_cleaned_data(filename):\n",
    "\treturn load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ORWdTFwKPh7G",
    "outputId": "8eef7755-b8e7-42fa-f77a-3e0ca06b35c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(192341, 3)\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "data = loading_cleaned_data('english-french.pkl')\n",
    "print(data.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p5RbRHzlL_oF"
   },
   "source": [
    "**Scaling of data** \n",
    "\n",
    "**Size**\n",
    "\n",
    "1.Dataset - 20000\n",
    "\n",
    "2.Training - 18000\n",
    "\n",
    "3.Testing - 2000   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gjGXDVkDcpAy",
    "outputId": "1fff4400-c7a2-4374-8b51-23fe1b2f83d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "english-french-both.pkl : Saved\n",
      "english-french-train.pkl : Saved\n",
      "english-french-test.pkl : Saved\n"
     ]
    }
   ],
   "source": [
    "# reducing dataset size (scaling) \n",
    "\n",
    "new_data_size = 20000\n",
    "dataset = data[:new_data_size, :]\n",
    "\n",
    "# randomly shuffling the dataset to get proper training and testing data\n",
    "shuffle(dataset)\n",
    "\n",
    "# splitting into training and testing (90%-10%)\n",
    "train, test = dataset[:18000], dataset[18000:]\n",
    "\n",
    "# saving the cleaned data,train data and test data \n",
    "saving_clean_data(dataset, 'english-french-both.pkl')\n",
    "saving_clean_data(train, 'english-french-train.pkl')\n",
    "saving_clean_data(test, 'english-french-test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "h-_XKg-UMojw"
   },
   "outputs": [],
   "source": [
    "# loading datasets and saving it into variables\n",
    "dataset = loading_cleaned_data('english-french-both.pkl')\n",
    "train = loading_cleaned_data('english-french-train.pkl')\n",
    "test = loading_cleaned_data('english-french-test.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Avp8Q0-xdaUj"
   },
   "source": [
    "**Creating a tokenizer for the lines and finding the maximum length phrase**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "wLD8OFAIPJUf"
   },
   "outputs": [],
   "source": [
    "# fit a tokenizer\n",
    "def create_tokenizer(lines):\n",
    "\ttokenizer = Tokenizer()\n",
    "\ttokenizer.fit_on_texts(lines)\n",
    "\treturn tokenizer\n",
    "\n",
    "# max sentence length\n",
    "def max_length(lines):\n",
    "\treturn max(len(line.split()) for line in lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cKvmKQxWeRPQ"
   },
   "source": [
    "**Size of English & French vocabulary and their max phrase length**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lDijv11iQ6CX",
    "outputId": "f33fe371-70a9-411b-aedd-d63f8e3fbe74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Vocabulary Size: 3418\n",
      "English Max Length: 5\n",
      "French Vocabulary Size: 6977\n",
      "French Max Length: 11\n"
     ]
    }
   ],
   "source": [
    "# preparing the english tokenizer\n",
    "\n",
    "eng_tokenizer = create_tokenizer(dataset[:, 0])\n",
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
    "eng_length = max_length(dataset[:, 0])\n",
    "\n",
    "print('English Vocabulary Size: %d' % eng_vocab_size)\n",
    "print('English Max Length: %d' % (eng_length))\n",
    "\n",
    "# preparing the french tokenizer\n",
    "\n",
    "fra_tokenizer = create_tokenizer(dataset[:, 1])\n",
    "fra_vocab_size = len(fra_tokenizer.word_index) + 1\n",
    "fra_length = max_length(dataset[:, 1])\n",
    "print('French Vocabulary Size: %d' % fra_vocab_size)\n",
    "print('French Max Length: %d' % (fra_length))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X3k5O2spejJH"
   },
   "source": [
    "**Encoding to integers and padding to the maximum phrase length**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "8WECbBTNRG5W"
   },
   "outputs": [],
   "source": [
    "# Input and Output sequence must be encoded to integers and padded to the maximum phrase length\n",
    "def encode_sequences(tokenizer, length, lines):\n",
    "\t# integer encode sequences\n",
    "\tx = tokenizer.texts_to_sequences(lines)\n",
    "\t# pad sequences with 0 values\n",
    "\tx = pad_sequences(x, maxlen=length, padding='post')\n",
    "\treturn x\n",
    "\n",
    "# One hot encoding to max phrase length\n",
    "def one_hot_encoding(sequences, vocab_size):\n",
    "\ty_1 = list()\n",
    "\tfor sequence in sequences:\n",
    "\t\tencoded = to_categorical(sequence, num_classes=vocab_size)\n",
    "\t\ty_1.append(encoded)\n",
    "\ty = array(y_1)\n",
    "\ty = y.reshape(sequences.shape[0], sequences.shape[1], vocab_size)\n",
    "\treturn y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9dvj7nZWf8c-"
   },
   "source": [
    "**Training and Testing Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "nj7j2bIWf78M"
   },
   "outputs": [],
   "source": [
    "# preparing training data\n",
    "trainX = encode_sequences(fra_tokenizer, fra_length, train[:, 1])\n",
    "trainY = encode_sequences(eng_tokenizer, eng_length, train[:, 0])\n",
    "trainY = one_hot_encoding(trainY, eng_vocab_size)\n",
    "\n",
    "# prepare testing data\n",
    "testX = encode_sequences(fra_tokenizer, fra_length, test[:, 1])\n",
    "testY = encode_sequences(eng_tokenizer,eng_length, test[:, 0])\n",
    "testY = one_hot_encoding(testY, eng_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g8xr_mwyFdRD",
    "outputId": "c4e25354-f84b-4886-c5f7-0d3f6a53ec5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training size: (18000, 11) (18000, 5, 3418)\n",
      "testing size: (2000, 11) (2000, 5, 3418)\n"
     ]
    }
   ],
   "source": [
    "print('training size:',trainX.shape,trainY.shape)\n",
    "print('testing size:',testX.shape,testY.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bs628M3JgpLZ"
   },
   "source": [
    "**Building the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "pBlM7AzcR-U_"
   },
   "outputs": [],
   "source": [
    "def model_building(source_vocab, target_vocab, source_len, target_len, units):\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Embedding(source_vocab, units, input_length=source_len, mask_zero=True))\n",
    "\tmodel.add(LSTM(units))\n",
    "\tmodel.add(RepeatVector(target_len))\n",
    "\tmodel.add(LSTM(units, return_sequences=True))\n",
    "\tmodel.add(TimeDistributed(Dense(target_vocab, activation='softmax')))\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HexQi4N7iLln"
   },
   "source": [
    "**Defining and Compiling the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "wOrjJUy8SECu"
   },
   "outputs": [],
   "source": [
    "model = model_building(fra_vocab_size, eng_vocab_size, fra_length, eng_length, 512)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V3ovCukmiRzW"
   },
   "source": [
    "**Model Summary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rwb8ibuDSUvW",
    "outputId": "cb158472-223e-4e30-a233-5744b7c2460d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 11, 512)           3572224   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 512)               2099200   \n",
      "                                                                 \n",
      " repeat_vector (RepeatVector  (None, 5, 512)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 5, 512)            2099200   \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, 5, 3418)          1753434   \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,524,058\n",
      "Trainable params: 9,524,058\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "d3_4Jn4RkNU9"
   },
   "outputs": [],
   "source": [
    "# Stop model if accuracy of the model doesn't changes by more than 0.01 \n",
    "# Patience = 5 : After each 5 epochs if no improvement is there then training will be stopped.\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(monitor='val_acc',patience= 5,min_delta=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8VP_QQwGiZrN"
   },
   "source": [
    "**Fitting the model**\n",
    "\n",
    "1.Epochs = 50\n",
    "\n",
    "2.Batch_size = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BI6ioDuaS57H",
    "outputId": "c166b7d8-49b9-4416-927a-7722c7350d54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "720/720 - 238s - loss: 3.6208 - acc: 0.4608 - val_loss: 3.1023 - val_acc: 0.5105 - 238s/epoch - 330ms/step\n",
      "Epoch 2/50\n",
      "720/720 - 248s - loss: 2.7518 - acc: 0.5509 - val_loss: 2.5777 - val_acc: 0.5802 - 248s/epoch - 345ms/step\n",
      "Epoch 3/50\n",
      "720/720 - 213s - loss: 2.1855 - acc: 0.6101 - val_loss: 2.2388 - val_acc: 0.6229 - 213s/epoch - 295ms/step\n",
      "Epoch 4/50\n",
      "720/720 - 219s - loss: 1.7404 - acc: 0.6578 - val_loss: 2.0150 - val_acc: 0.6485 - 219s/epoch - 305ms/step\n",
      "Epoch 5/50\n",
      "720/720 - 217s - loss: 1.3641 - acc: 0.7049 - val_loss: 1.8703 - val_acc: 0.6700 - 217s/epoch - 302ms/step\n",
      "Epoch 6/50\n",
      "720/720 - 219s - loss: 1.0443 - acc: 0.7575 - val_loss: 1.7843 - val_acc: 0.6859 - 219s/epoch - 305ms/step\n",
      "Epoch 7/50\n",
      "720/720 - 197s - loss: 0.7882 - acc: 0.8055 - val_loss: 1.6957 - val_acc: 0.7106 - 197s/epoch - 273ms/step\n",
      "Epoch 8/50\n",
      "720/720 - 201s - loss: 0.5908 - acc: 0.8479 - val_loss: 1.6537 - val_acc: 0.7194 - 201s/epoch - 279ms/step\n",
      "Epoch 9/50\n",
      "720/720 - 214s - loss: 0.4492 - acc: 0.8802 - val_loss: 1.6518 - val_acc: 0.7288 - 214s/epoch - 297ms/step\n",
      "Epoch 10/50\n",
      "720/720 - 181s - loss: 0.3528 - acc: 0.9028 - val_loss: 1.6580 - val_acc: 0.7352 - 181s/epoch - 251ms/step\n",
      "Epoch 11/50\n",
      "720/720 - 191s - loss: 0.2879 - acc: 0.9180 - val_loss: 1.6591 - val_acc: 0.7361 - 191s/epoch - 266ms/step\n",
      "Epoch 12/50\n",
      "720/720 - 256s - loss: 0.2475 - acc: 0.9272 - val_loss: 1.6907 - val_acc: 0.7396 - 256s/epoch - 355ms/step\n",
      "Epoch 13/50\n",
      "720/720 - 228s - loss: 0.2203 - acc: 0.9328 - val_loss: 1.7239 - val_acc: 0.7375 - 228s/epoch - 317ms/step\n",
      "Epoch 14/50\n",
      "720/720 - 226s - loss: 0.2035 - acc: 0.9362 - val_loss: 1.7339 - val_acc: 0.7372 - 226s/epoch - 313ms/step\n",
      "Epoch 15/50\n",
      "720/720 - 215s - loss: 0.1919 - acc: 0.9379 - val_loss: 1.7422 - val_acc: 0.7348 - 215s/epoch - 299ms/step\n",
      "Epoch 16/50\n",
      "720/720 - 212s - loss: 0.1840 - acc: 0.9399 - val_loss: 1.7569 - val_acc: 0.7401 - 212s/epoch - 294ms/step\n",
      "Epoch 17/50\n",
      "720/720 - 217s - loss: 0.1788 - acc: 0.9403 - val_loss: 1.7572 - val_acc: 0.7396 - 217s/epoch - 301ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26681cd6d00>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model\n",
    "model.fit(trainX, trainY, epochs= 50, batch_size=25, validation_data=(testX, testY), verbose=2,callbacks=[es])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PamgrtO1tc81"
   },
   "source": [
    "**Evaluating model and calculating BLEU Score**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5jpeIlnvNTyK"
   },
   "source": [
    "Evaluation involves two steps: \n",
    "\n",
    "1.Generating a translated output sequence, and \n",
    "\n",
    "2.then repeating this process for many input examples and summarizing the skill of the model across multiple cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "vjz4ERSYT1Df"
   },
   "outputs": [],
   "source": [
    "# mapping integer to a word\n",
    "def word_for_id(integer, tokenizer):\n",
    "\tfor word, index in tokenizer.word_index.items():\n",
    "\t\tif index == integer:\n",
    "\t\t\treturn word\n",
    "\treturn None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "XZV4Qm51TxdH"
   },
   "outputs": [],
   "source": [
    "# generating target given source sequence\n",
    "def predict_sequence(model, tokenizer, source):\n",
    "\tprediction = model.predict(source, verbose=0)[0]\n",
    "\tintegers = [argmax(vector) for vector in prediction]\n",
    "\ttarget = list()\n",
    "\tfor i in integers:\n",
    "\t\tword = word_for_id(i, tokenizer)\n",
    "\t\tif word is None:\n",
    "\t\t\tbreak\n",
    "\t\ttarget.append(word)\n",
    "\treturn ' '.join(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "_pHVBAejXOA1"
   },
   "outputs": [],
   "source": [
    "\n",
    "# evaluating the skill of the model\n",
    "def evaluate_model(model, tokenizer, sources, raw_dataset):\n",
    "  \n",
    "  # Creating empty lists for actual phrases(French) and predicted phrases(English) \n",
    "  actual,predicted = list(),list()\n",
    "  a,b,c = list(),list(),list()\n",
    "  for i,source in enumerate(sources):\n",
    "\n",
    "    # reshaping to the required size\n",
    "    source = source.reshape((1, source.shape[0]))\n",
    "\n",
    "    # predicting for the english tokenizer\n",
    "    translation = predict_sequence(model, eng_tokenizer, source)\n",
    "    # raw_dataset = raw_dataset[i].split(' ') \n",
    "    # print(raw_dataset[i][1])\n",
    "\n",
    "    raw_src,raw_target = raw_dataset[i][1],raw_dataset[i][0]\n",
    "    \n",
    "    # First 10 Predictions\n",
    "    if i <= 10:\n",
    "      print('source = ',raw_src,'<--->', ' target = ',raw_target,'<--->','  predicted = ',translation)\n",
    "\n",
    "    actual.append([raw_target.split()])\n",
    "    predicted.append(translation.split())\n",
    "  \n",
    "  # calculating BLEU score\n",
    "  print('-------------------------------------------')\n",
    "  print('BLEU Score :')\n",
    "  print('BLEU score-1: %f' % corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0),smoothing_function=smoothie,auto_reweigh=False))\n",
    "  print('BLEU score-2: %f' % corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0),smoothing_function=smoothie,auto_reweigh=False))\n",
    "  print('BLEU score-3: %f' % corpus_bleu(actual, predicted, weights=(0.3, 0.3, 0.3, 0),smoothing_function=smoothie,auto_reweigh=False))\n",
    "  print('BLEU score-4: %f' % corpus_bleu(actual, predicted, weights=(0.25, 0.25, 0.25, 0.25),smoothing_function=smoothie,auto_reweigh=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TnrScoRlPafY"
   },
   "source": [
    "**Evaluating Model on training data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q42oWYQuWhSw",
    "outputId": "90053f9b-4d1d-4300-d37d-75067581ab39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source =  jadore les enigmes <--->  target =  i love puzzles <--->   predicted =  i love puzzles\n",
      "source =  la radio est allumee <--->  target =  the radio is on <--->   predicted =  the radio is on\n",
      "source =  tom a ete cruel <--->  target =  tom was cruel <--->   predicted =  tom was cruel\n",
      "source =  ne sois pas si lent <--->  target =  dont be so slow <--->   predicted =  dont be so slow\n",
      "source =  jen veux une aussi <--->  target =  i want one too <--->   predicted =  i want one too\n",
      "source =  ils sont pieges <--->  target =  theyre trapped <--->   predicted =  theyre trapped\n",
      "source =  tom aida <--->  target =  tom helped <--->   predicted =  tom helped\n",
      "source =  je me suis blesse <--->  target =  i got hurt <--->   predicted =  i got hurt\n",
      "source =  il deteste courir <--->  target =  he hates running <--->   predicted =  he hates running\n",
      "source =  tout est faux <--->  target =  its all wrong <--->   predicted =  its all wrong\n",
      "source =  combien cela coutetil <--->  target =  how much is that <--->   predicted =  how much is that\n",
      "-------------------------------------------\n",
      "BLEU Score :\n",
      "BLEU score-1: 0.934987\n",
      "BLEU score-2: 0.916089\n",
      "BLEU score-3: 0.854939\n",
      "BLEU score-4: 0.600696\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model,eng_tokenizer,trainX,train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sgxS1flZPjNJ"
   },
   "source": [
    "**Evaluating Model on testing data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QIsBhu9N5wfx",
    "outputId": "a45d7f83-50f1-49e6-c081-4ea9026ad9c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source =  ne touche pas a ceci <--->  target =  dont touch this <--->   predicted =  dont touch that\n",
      "source =  tom peut parler <--->  target =  tom can talk <--->   predicted =  tom can talk\n",
      "source =  je ne suis pas normale <--->  target =  im not normal <--->   predicted =  im not normal\n",
      "source =  verrouillez le coffrefort <--->  target =  lock the safe <--->   predicted =  lock the safe\n",
      "source =  jai ete secouee <--->  target =  i was shaken <--->   predicted =  i was attacked\n",
      "source =  je pourrais etre le prochain <--->  target =  i could be next <--->   predicted =  i could feel well\n",
      "source =  quand cela sestil termine <--->  target =  when did it end <--->   predicted =  when does it\n",
      "source =  souriez je vous prie <--->  target =  please smile <--->   predicted =  please please\n",
      "source =  je suis plus rapide <--->  target =  im faster <--->   predicted =  im am\n",
      "source =  tom est deteste <--->  target =  tom is hated <--->   predicted =  tom is\n",
      "source =  tout le monde vatil bien <--->  target =  is everybody ok <--->   predicted =  everyones all\n",
      "-------------------------------------------\n",
      "BLEU Score :\n",
      "BLEU score-1: 0.628703\n",
      "BLEU score-2: 0.530144\n",
      "BLEU score-3: 0.462437\n",
      "BLEU score-4: 0.272598\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model, eng_tokenizer, testX, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras as ks\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_file = \"translator.h5\"\n",
    "tf.keras.models.save_model(model,keras_file)\n",
    "converter = lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.experimental_new_converter=True\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,\n",
    "tf.lite.OpsSet.SELECT_TF_OPS]\n",
    "\n",
    "tfmodel = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open(\"translator.tflite\",\"wb\").write(tfmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Neural Machine Translation French-English.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
